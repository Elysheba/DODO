Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Saqi2019,
abstract = {Large amounts of data emerging from experiments in molecular medicine are leading to the identification of molecular signatures associated with disease subtypes. The contextualization of these patterns is important for obtaining mechanistic insight into the aberrant processes associated with a disease, and this typically involves the integration of multiple heterogeneous types of data. In this review, we discuss knowledge representations that can be useful to explore the biological context of molecular signatures, in particular three main approaches, namely, pathway mapping approaches, molecular network centric approaches and approaches that represent biological statements as knowledge graphs. We discuss the utility of each of these paradigms, illustrate how they can be leveraged with selected practical examples and identify ongoing challenges for this field of research.},
author = {Saqi, Mansoor and Lysenko, Artem and Guo, Yi Ke and Tsunoda, Tatsuhiko and Auffray, Charles},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Saqi et al. - 2019.pdf:pdf},
journal = {Brief. Bioinform.},
keywords = {disease modeling,integrated knowledge networks,molecular medicine,multi-omics,precision medicine},
number = {2},
pages = {609--623},
title = {{Navigating the disease landscape: Knowledge representations for contextualizing molecular signatures}},
volume = {20},
year = {2019}
}
@article{Valle2019,
abstract = {Over a decade ago, a new discipline called network medicine emerged as an approach to understand human diseases from a network theory point-of-view. Disease networks proved to be an intuitive and powerful way to reveal hidden connections among apparently unconnected biomedical entities such as diseases, physiological processes, signaling pathways, and genes. One of the fields that has benefited most from this improvement is the identification of new opportunities for the use of old drugs, known as drug repurposing. The importance of drug repurposing lies in the high costs and the prolonged time from target selection to regulatory approval of traditional drug development. In this document we analyze the evolution of disease network concept during the last decade and apply a data science pipeline approach to evaluate their functional units. As a result of this analysis, we obtain a list of the most commonly used functional units and the challenges that remain to be solved. This information can be very valuable for the generation of new prediction models based on disease networks.},
author = {del Valle, Eduardo Garcia and Garcia, Gerardo Lagunes and Santamaria, Lucia Prieto and Zanin, Massimiliano and Ruiz, Ernestina Menasalvas and Gonzalez, Alejandro Rodriguez},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Valle et al. - 2019.pdf:pdf},
journal = {bioRxiv},
pages = {415257},
title = {{Disease networks and their contribution to disease understanding and drug repurposing: Evolution of the concept, techniques and data sources}},
url = {https://www.biorxiv.org/content/10.1101/415257v3?rss=1},
year = {2019}
}
@article{Lachmann2018,
abstract = {RNA sequencing (RNA-seq) is the leading technology for genome-wide transcript quantification. However, publicly available RNA-seq data is currently provided mostly in raw form, a significant barrier for global and integrative retrospective analyses. ARCHS4 is a web resource that makes the majority of published RNA-seq data from human and mouse available at the gene and transcript levels. For developing ARCHS4, available FASTQ files from RNA-seq experiments from the Gene Expression Omnibus (GEO) were aligned using a cloud-based infrastructure. In total 187,946 samples are accessible through ARCHS4 with 103,083 mouse and 84,863 human. Additionally, the ARCHS4 web interface provides intuitive exploration of the processed data through querying tools, interactive visualization, and gene pages that provide average expression across cell lines and tissues, top co-expressed genes for each gene, and predicted biological functions and protein-protein interactions for each gene based on prior knowledge combined with co-expression.},
author = {Lachmann, Alexander and Torre, Denis and Keenan, Alexandra B. and Jagodnik, Kathleen M. and Lee, Hoyjin J. and Wang, Lily and Silverstein, Moshe C. and Ma'ayan, Avi},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Lachmann et al. - 2018.pdf:pdf},
journal = {Nat. Commun.},
number = {1},
publisher = {Springer US},
title = {{Massive mining of publicly available RNA-seq data from human and mouse}},
volume = {9},
year = {2018}
}
@article{Hu2017,
abstract = {Database URL: http://ws.nju.edu.cn/biosearch/.},
author = {Hu, Wei and Qiu, Honglei and Huang, Jiacheng and Dumontier, Michel},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Hu et al. - 2017.pdf:pdf},
journal = {Database (Oxford).},
pages = {1--13},
title = {{BioSearch: a semantic search engine for Bio2RDF}},
volume = {2017},
year = {2017}
}
@misc{Akil2011,
abstract = {Understanding the brain requires a broad range of approaches and methods from the domains of biology, psychology, chemistry, physics, and mathematics. The fundamental challenge is to decipher the "neural choreography" associated with complex behaviors and functions, including thoughts, memories, actions, and emotions. This demands the acquisition and integration of vast amounts of data of many types, at multiple scales in time and in space. Here we discuss the need for neuroinformatics approaches to accelerate progress, using several illustrative examples. The nascent field of "connectomics" aims to comprehensively describe neuronal connectivity at either a macroscopic level (in long-distance pathways for the entire brain) or a microscopic level (among axons, dendrites, and synapses in a small brain region). The Neuroscience Information Framework (NIF) encompasses all of neuroscience and facilitates the integration of existing knowledge and databases of many types. These examples illustrate the opportunities and challenges of data mining across multiple tiers of neuroscience information and underscore the need for cultural and infrastructure changes if neuroinformatics is to fulfill its potential to advance our understanding of the brain.},
author = {Akil, Huda and Martone, Maryann E and {Van Essen}, David C.},
booktitle = {Science (80-. ).},
doi = {10.1126/science.1199305},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Akil, Martone, Van Essen - 2011.pdf:pdf},
issn = {00368075},
number = {6018},
pages = {708--712},
title = {{Challenges and opportunities in mining neuroscience data}},
volume = {331},
year = {2011}
}
@misc{Pendlington2019,
author = {Pendlington, Zo{\"{e}} May and Carvalho-Silva, Denise},
title = {{Avoiding confusion in disease biology with ontologies}},
url = {http://blog.opentargets.org/2019/04/05/avoiding-confusion-in-disease-biology-with-ontologies/},
year = {2019}
}
@article{Goble2001,
abstract = {This paper describes the Transparent Access to Multiple Bioinformatics Information Sources project, known as TAMBIS, in which a domain ontology for molecular biology and bioinformatics is used in a retrieval-based information integration system for biologists. The ontology, represented using a description logic and managed by a terminology server, is used both to drive a visual query interface and as a global schema against which complex intersource queries are expressed. These source-independent declarative queries are then rewritten into collections of ordered source-dependent queries for execution by a middleware layer. In bioinformatics, the majority of data sources are not databases but tools with limited accessible interfaces. The ontology helps manage the interoperation between these resources. The paper emphasizes the central role that is played by the ontology in the system. The project distinguishes itself from others in the following ways: The ontology, developed by a biologist, is substantial; the retrieval interface is sophisticated; the description logic is managed by a sophisticated terminology server. A full pilot application is available as a JavaTM applet integrating five sources concerned with proteins. This pilot is currently undergoing field trials with working biologists and is being used to answer real questions in biology, one of which is used as a case study throughout the paper.},
author = {Goble, C. A. and Stevens, R. and Ng, G. and Bechhofer, S. and Paton, N. W. and Baker, P. G. and Peim, M. and Brass, A.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Goble et al. - 2001.pdf:pdf},
journal = {IBM Syst. J.},
number = {2},
pages = {532--551},
title = {{Transparent access to multiple bioinformatics information sources}},
volume = {40},
year = {2001}
}
@article{Berlanga2012,
abstract = {The semantic integration of biomedical resources is still a challenging issue which is required for effective information processing and data analysis. The availability of comprehensive knowledge resources such as biomedical ontologies and integrated thesauri greatly facilitates this integration effort by means of semantic annotation, which allows disparate data formats and contents to be expressed under a common semantic space. In this paper, we propose a multidimensional representation for such a semantic space, where dimensions regard the different perspectives in biomedical research (e.g., population, disease, anatomy and protein/genes). This paper presents a novel method for building multidimensional semantic spaces from semantically annotated biomedical data collections. This method consists of two main processes: knowledge and data normalization. The former one arranges the concepts provided by a reference knowledge resource (e.g., biomedical ontologies and thesauri) into a set of hierarchical dimensions for analysis purposes. The latter one reduces the annotation set associated to each collection item into a set of points of the multidimensional space. Additionally, we have developed a visual tool, called 3D-Browser, which implements OLAP-like operators over the generated multidimensional space. The method and the tool have been tested and evaluated in the context of the Health-e-Child (HeC) project. Automatic semantic annotation was applied to tag three collections of abstracts taken from PubMed, one for each target disease of the project, the Uniprot database, and the HeC patient record database. We adopted the UMLS Meta-thesaurus 2010AA as the reference knowledge resource. Current knowledge resources and semantic-aware technology make possible the integration of biomedical resources. Such an integration is performed through semantic annotation of the intended biomedical data resources. This paper shows how these annotations can be exploited for integration, exploration, and analysis tasks. Results over a real scenario demonstrate the viability and usefulness of the approach, as well as the quality of the generated multidimensional semantic spaces.},
author = {Berlanga, Rafael and Jim{\'{e}}nez-Ruiz, Ernesto and Nebot, Victoria},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Berlanga, Jim{\'{e}}nez-Ruiz, Nebot - 2012.pdf:pdf},
journal = {BMC Bioinformatics},
number = {Suppl 1},
pages = {1--17},
title = {{Exploring and linking biomedical resources through multidimensional semantic spaces.}},
volume = {13 Suppl 1},
year = {2012}
}
@misc{Wickham2018,
author = {Wickham, Hadly and Hester, Jim and Fran{\c{c}}ois, Romain},
title = {{readr: Read Rectangular Text Data}},
year = {2018}
}
@misc{Muller2019,
author = {M{\"{u}}ller, Kirill and Wickham, Hadly},
title = {tibble: simple data frames},
url = {https://cran.r-project.org/package=tibble},
year = {2019}
}
@article{Belleau2008,
abstract = {Presently, there are numerous bioinformatics databases available on different websites. Although RDF was proposed as a standard format for the web, these databases are still available in various formats. With the increasing popularity of the semantic web technologies and the ever growing number of databases in bioinformatics, there is a pressing need to develop mashup systems to help the process of bioinformatics knowledge integration. Bio2RDF is such a system, built from rdfizer programs written in JSP, the Sesame open source triplestore technology and an OWL ontology. With Bio2RDF, documents from public bioinformatics databases such as Kegg, PDB, MGI, HGNC and several of NCBI's databases can now be made available in RDF format through a unique URL in the form of http://bio2rdf.org/namespace:id. The Bio2RDF project has successfully applied the semantic web technology to publicly available databases by creating a knowledge space of RDF documents linked together with normalized URIs and sharing a common ontology. Bio2RDF is based on a three-step approach to build mashups of bioinformatics data. The present article details this new approach and illustrates the building of a mashup used to explore the implication of four transcription factor genes in Parkinson's disease. The Bio2RDF repository can be queried at http://bio2rdf.org. {\textcopyright} 2008 Elsevier Inc. All rights reserved.},
author = {Belleau, Fran{\c{c}}ois and Nolin, Marc Alexandre and Tourigny, Nicole and Rigault, Philippe and Morissette, Jean},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Belleau et al. - 2008.pdf:pdf},
journal = {J. Biomed. Inform.},
keywords = {Bioinformatics database,Knowledge integration,Mashup,Ontology,Semantic web},
number = {5},
pages = {706--716},
title = {{Bio2RDF: Towards a mashup to build bioinformatics knowledge systems}},
volume = {41},
year = {2008}
}
@misc{MONDO2019,
author = {MONDO},
publisher = {[Last visit 26/12/2019]},
title = {{Monarch Disease Ontology: Sources}},
url = {https://mondo.monarchinitiative.org/pages/sources/},
year = {2019}
}
@article{Ong2017,
abstract = {Linked Data (LD) aims to achieve interconnected data by representing entities using Unified Resource Identifiers (URIs), and sharing information using Resource Description Frameworks (RDFs) and HTTP. Ontologies, which logically represent entities and relations in specific domains, are the basis of LD. Ontobee (http://www.ontobee.org/) is a linked ontology data server that stores ontology information using RDF triple store technology and supports query, visualization and linkage of ontology terms. Ontobee is also the default linked data server for publishing and browsing biomedical ontologies in the Open Biological Ontology (OBO) Foundry (http://obofoundry.org) library. Ontobee currently hosts more than 180 ontologies (including 131 OBO Foundry Library ontologies) with over four million terms. Ontobee provides a user-friendly web interface for querying and visualizing the details and hierarchy of a specific ontology term. Using the eXtensible Stylesheet Language Transformation (XSLT) technology, Ontobee is able to dereference a single ontology term URI, and then output RDF/eXtensible Markup Language (XML) for computer processing or display the HTML information on a web browser for human users. Statistics and detailed information are generated and displayed for each ontology listed in Ontobee. In addition, a SPARQL web interface is provided for custom advanced SPARQL queries of one or multiple ontologies.},
author = {Ong, Edison and Xiang, Zuoshuang and Zhao, Bin and Liu, Yue and Lin, Yu and Zheng, Jie and Mungall, Chris and Courtot, M{\'{e}}lanie and Ruttenberg, Alan and He, Yongqun},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Ong et al. - 2017.pdf:pdf},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {D347--D352},
title = {{Ontobee: A linked ontology data server to support ontology term dereferencing, linkage, query and integration}},
volume = {45},
year = {2017}
}
@article{Kohler2014,
abstract = {Phenotype analyses, e.g. investigating metabolic processes, tissue formation, or organism behavior, are an important element of most biological and medical research activities. Biomedical researchers are making increased use of ontological standards and methods to capture the results of such analyses, with one focus being the comparison and analysis of phenotype information between species. We have generated a cross-species phenotype ontology for human, mouse and zebrafish that contains classes from the Human Phenotype Ontology, Mammalian Phenotype Ontology, and generated classes for zebrafish phenotypes. We also provide up-to-date annotation data connecting human genes to phenotype classes from the generated ontology. We have included the data generation pipeline into our continuous integration system ensuring stable and up-to-date releases. This article describes the data generation process and is intended to help interested researchers access both the phenotype annotation data and the associated cross-species phenotype ontology. The resource described here can be used in sophisticated semantic similarity and gene set enrichment analyses for phenotype data across species. The stable releases of this resource can be obtained from http://purl.obolibrary.org/obo/hp/uberpheno/.},
author = {K{\"{o}}hler, Sebastian and Doelken, Sandra C and Ruef, Barbara J and Bauer, Sebastian and Washington, Nicole and Westerfield, Monte and Gkoutos, George and Schofield, Paul and Smedley, Damian and Lewis, Suzanna E and Robinson, Peter N and Mungall, Christopher J},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/K{\"{o}}hler et al. - 2014.pdf:pdf},
journal = {F1000Research},
number = {0},
pages = {1--13},
title = {{Construction and accessibility of a cross-species phenotype ontology along with gene annotations for biomedical research}},
year = {2014}
}
@article{Kibbe2015,
abstract = {The current version of the Human Disease Ontology (DO) (http://www.disease-ontology.org) database expands the utility of the ontology for the examination and comparison of genetic variation, phenotype, protein, drug and epitope data through the lens of human disease. DO is a biomedical resource of standardized common and rare disease concepts with stable identifiers organized by disease etiology. The content of DO has had 192 revisions since 2012, including the addition of 760 terms. Thirty-two percent of all terms now include definitions. DO has expanded the number and diversity of research communities and community members by 50+ during the past two years. These community members actively submit term requests, coordinate biomedical resource disease representation and provide expert curation guidance. Since the DO 2012 NAR paper, there have been hundreds of term requests and a steady increase in the number of DO listserv members, twitter followers and DO website usage. DO is moving to a multi-editor model utilizing Prot{\'{e}}g{\'{e}} to curate DO in web ontology language. This will enable closer collaboration with the Human Phenotype Ontology, EBI's Ontology Working Group, Mouse Genome Informatics and the Monarch Initiative among others, and enhance DO's current asserted view and multiple inferred views through reasoning.},
author = {Kibbe, Warren A. and Arze, Cesar and Felix, Victor and Mitraka, Elvira and Bolton, Evan and Fu, Gang and Mungall, Christopher J. and Binder, Janos X. and Malone, James and Vasant, Drashtti and Parkinson, Helen and Schriml, Lynn M.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Kibbe et al. - 2015.pdf:pdf},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {D1071--D1078},
title = {{Disease Ontology 2015 update: An expanded and updated database of Human diseases for linking biomedical knowledge through disease data}},
volume = {43},
year = {2015}
}
@article{Godard2018,
abstract = {The understanding of molecular processes involved in a specific biological system can be significantly improved by combining and comparing different data sets and knowledge resources. However, these information sources often use different identification systems and an identifier conversion step is required before any integration effort. Mapping between identifiers is often provided by the reference information resources and several tools have been implemented to simplify their use. However, most of these tools do not combine the information provided by individual resources to increase the completeness of the mapping process. Also, deprecated identifiers from former versions of databases are not taken into account. Finally, finding automatically the most relevant path to map identifiers from one scope to the other is often not trivial. The Biological Entity Dictionary (BED) addresses these three challenges by relying on a graph data model describing possible relationships between entities and their identifiers. This model has been implemented using Neo4j and an R package provides functions to query the graph but also to create and feed a custom instance of the database. This design combined with a local installation of the graph database and a cache system make BED very efficient to convert large lists of identifiers.},
author = {Godard, Patrice and van Eyll, Jonathan},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Godard, van Eyll - 2018.pdf:pdf},
journal = {F1000Research},
keywords = {Database,Genomics,Identifiers,Microarray,Proteomics,RNA-seq,Transcriptomics},
pages = {1--32},
title = {{BED: A Biological Entity Dictionary based on a graph data model [version 2; referees: 2 approved]}},
volume = {7},
year = {2018}
}
@article{Jupp2012,
abstract = {We present a technique for separating knowledge representation from application specific views that are currently often conflated within bio-ontologies. Many ontologies contain information for two tasks; one to represent the knowledge of some field of interest and another to support an application through providing views over ontologies that present the terms in a useful way for an application. We analyse this phenomenon in some bio-ontologies and suggest this separation of layers as a solution. We leave dedicated ontology languages like OWL and OBO to represent the knowledge of a field of interest, and use a more lightweight vocabulary, namely SKOS, to capture application specific views. We use this technique to encode a number of views inside the Experimental Factor Ontology. Each of these views serves a special purpose to different user communities; however, it does ensure the underlying ontology can remain for the annotation and integration of biological data. OWL and SKOS together provide a powerful, standards based, mechanism to reconstitute annotated biological data for many different application domains.},
author = {Jupp, Simon and Gibson, Andrew and Malone, James and Parkinson, Helen and Stevens, Robert},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Jupp et al. - 2012.pdf:pdf},
journal = {CEUR Workshop Proc.},
pages = {1--5},
title = {{Taking a view on bio-ontologies}},
volume = {897},
year = {2012}
}
@misc{Wickham2019,
author = {Wickham, Hadly and Fran{\c{c}}ois, Romain and Henry, Lionel and M{\"{u}}ller, Kirill},
title = {dplyr: a grammar of data manipulation},
url = {https://cran.r-project.org/package=dplyr},
year = {2019}
}
@article{Hasnain2014,
abstract = {The increase in the volume and heterogeneity of biomedical data sources has motivated researchers to embrace Linked Data (LD) technologies to solve the ensuing integration challenges and enhance information discovery. As an integral part of the EU GRANATUM project, a Linked Biomedical Dataspace (LBDS) was developed to semantically interlink data from multiple sources and augment the design of in silico experiments for cancer chemoprevention drug discovery. The different components of the LBDS facilitate both the bioinformaticians and the biomedical researchers to publish, link, query and visually explore the heterogeneous datasets. We have extensively evaluated the usability of the entire platform. In this paper, we showcase three different workflows depicting real-world scenarios on the use of LBDS by the domain users to intuitively retrieve meaningful information from the integrated sources. We report the important lessons that we learned through the challenges encountered and our accumulated experience during the collaborative processes which would make it easier for LD practitioners to create such dataspaces in other domains. We also provide a concise set of generic recommendations to develop LD platforms useful for drug discovery.},
author = {Hasnain, Ali and Kamdar, Maulik R. and Hasapis, Panagiotis and Zeginis, Dimitris and Warren, Claude N. and Deus, Helena F. and Ntalaperas, Dimitrios and Tarabanis, Konstantinos and Mehdi, Muntazir and Decker, Stefan},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Hasnain et al. - 2014.pdf:pdf},
journal = {Lect. Notes Comput. Sci. (including Subser. Lect. Notes Artif. Intell. Lect. Notes Bioinformatics)},
keywords = {Biomedical research,Drug discovery,Linked data,SPARQL federation,Visualization},
pages = {114--130},
title = {{Linked biomedical dataspace: Lessons learned integrating data for drug discovery}},
volume = {8796},
year = {2014}
}
@article{Cheng2013,
abstract = {Background:A number of databases have been developed to collect disease-related molecular, phenotypic and environmental features (DR-MPEs), such as genes, non-coding RNAs, genetic variations, drugs, phenotypes and environmental factors. However, each of current databases focused on only one or two DR-MPEs. There is an urgent demand to develop an integrated database, which can establish semantic associations among disease-related databases and link them to provide a global view of human disease at the biological level. This database, once developed, will facilitate researchers to query various DR-MPEs through disease, and investigate disease mechanisms from different types of data.Methodology:To establish an integrated disease-associated database, disease vocabularies used in different databases are mapped to Disease Ontology (DO) through semantic match. 4,284 and 4,186 disease terms from Medical Subject Headings (MeSH) and Online Mendelian Inheritance in Man (OMIM) respectively are mapped to DO. Then, the relationships between DR-MPEs and diseases are extracted and merged from different source databases for reducing the data redundancy.Conclusions:A semantically integrated disease-associated database (SIDD) is developed, which integrates 18 disease-associated databases, for researchers to browse multiple types of DR-MPEs in a view. A web interface allows easy navigation for querying information through browsing a disease ontology tree or searching a disease term. Furthermore, a network visualization tool using Cytoscape Web plugin has been implemented in SIDD. It enhances the SIDD usage when viewing the relationships between diseases and DR-MPEs. The current version of SIDD (Jul 2013) documents 4,465,131 entries relating to 139,365 DR-MPEs, and to 3,824 human diseases. The database can be freely accessed from: http://mlg.hit.edu.cn/SIDD. {\textcopyright} 2013 Cheng et al.},
author = {Cheng, Liang and Wang, Guohua and Li, Jie and Zhang, Tianjiao and Xu, Peigang and Wang, Yadong},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Cheng et al. - 2013.pdf:pdf},
journal = {PLoS One},
number = {10},
pages = {1--9},
title = {{SIDD: A Semantically Integrated Database towards a Global View of Human Disease}},
volume = {8},
year = {2013}
}
@article{Pinero2015,
abstract = {DisGeNET is a comprehensive discovery platform designed to address a variety of questions concerning the genetic underpinning of human diseases. DisGeNET contains over 380 000 associations between {\textgreater}16 000 genes and 13 000 diseases, which makes it one of the largest repositories currently available of its kind. DisGeNET integrates expert-curated databases with text-mined data, covers information on Mendelian and complex diseases, and includes data from animal disease models. It features a score based on the supporting evidence to prioritize gene-disease associations. It is an open access resource available through a web interface, a Cytoscape plugin and as a Semantic Web resource. The web interface supports user-friendly data exploration and navigation. DisGeNET data can also be analysed via the DisGeNET Cytoscape plugin, and enriched with the annotations of other plugins of this popular network analysis software suite. Finally, the information contained in DisGeNET can be expanded and complemented using Semantic Web technologies and linked to a variety of resources already present in the Linked Data cloud. Hence, DisGeNET offers one of the most comprehensive collections of human gene-disease associations and a valuable set of tools for investigating the molecular mechanisms underlying diseases of genetic origin, designed to fulfill the needs of different user profiles, including bioinformaticians, biologists and health-care practitioners.},
author = {Pi{\~{n}}ero, Janet and Queralt-Rosinach, N{\'{u}}ria and Bravo, {\`{A}}lex and Deu-Pons, Jordi and Bauer-Mehren, Anna and Baron, Martin and Sanz, Ferran and Furlong, Laura I},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Pi{\~{n}}ero et al. - 2015.pdf:pdf},
journal = {Database},
pages = {1--17},
title = {{DisGeNET: A discovery platform for the dynamical exploration of human diseases and their genes}},
volume = {2015},
year = {2015}
}
@article{Haendel2018,
author = {Haendel, Melissa A and Mcmurry, Julie A and Relevo, Rose and Mungall, Christopher J and Peter, N and Chute, Christopher G},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Haendel et al. - 2018.pdf:pdf},
journal = {Annu. Rev. Biomed. Data Sci.},
pages = {305--331},
title = {{A Census of Disease Ontologies}},
volume = {1},
year = {2018}
}
@article{Haendel2014,
abstract = {BACKGROUND: Elucidating disease and developmental dysfunction requires understanding variation in phenotype. Single-species model organism anatomy ontologies (ssAOs) have been established to represent this variation. Multi-species anatomy ontologies (msAOs; vertebrate skeletal, vertebrate homologous, teleost, amphibian AOs) have been developed to represent 'natural' phenotypic variation across species. Our aim has been to integrate ssAOs and msAOs for various purposes, including establishing links between phenotypic variation and candidate genes.$\backslash$n$\backslash$nRESULTS: Previously, msAOs contained a mixture of unique and overlapping content. This hampered integration and coordination due to the need to maintain cross-references or inter-ontology equivalence axioms to the ssAOs, or to perform large-scale obsolescence and modular import. Here we present the unification of anatomy ontologies into Uberon, a single ontology resource that enables interoperability among disparate data and research groups. As a consequence, independent development of TAO, VSAO, AAO, and vHOG has been discontinued.$\backslash$n$\backslash$nCONCLUSIONS: The newly broadened Uberon ontology is a unified cross-taxon resource for metazoans (animals) that has been substantially expanded to include a broad diversity of vertebrate anatomical structures, permitting reasoning across anatomical variation in extinct and extant taxa. Uberon is a core resource that supports single- and cross-species queries for candidate genes using annotations for phenotypes from the systematics, biodiversity, medical, and model organism communities, while also providing entities for logical definitions in the Cell and Gene Ontologies. THE ONTOLOGY RELEASE FILES ASSOCIATED WITH THE ONTOLOGY MERGE DESCRIBED IN THIS MANUSCRIPT ARE AVAILABLE AT: http://purl.obolibrary.org/obo/uberon/releases/2013-02-21/ CURRENT ONTOLOGY RELEASE FILES ARE AVAILABLE ALWAYS AVAILABLE AT: http://purl.obolibrary.org/obo/uberon/releases/},
author = {Haendel, Melissa A. and Balhoff, James P. and Bastian, Frederic B. and Blackburn, David C. and Blake, Judith A. and Bradford, Yvonne and Comte, Aurelie and Dahdul, Wasila M. and Dececchi, Thomas A. and Druzinsky, Robert E. and Hayamizu, Terry F. and Ibrahim, Nizar and Lewis, Suzanna E. and Mabee, Paula M. and Niknejad, Anne and Robinson-Rechavi, Marc and Sereno, Paul C. and Mungall, Christopher J.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Haendel et al. - 2014.pdf:pdf},
journal = {J. Biomed. Semantics},
keywords = {Bio-ontology,Evolutionary biology,Morphological variation,Phenotype,Semantic integration},
number = {1},
pages = {1--13},
title = {{Unification of multi-species vertebrate anatomy ontologies for comparative biology in Uberon}},
volume = {5},
year = {2014}
}
@article{Musen2012,
abstract = {The National Center for Biomedical Ontology is now in its seventh year. The goals of this National Center for Biomedical Computing are to: create and maintain a repository of biomedical ontologies and terminologies; build tools and web services to enable the use of ontologies and terminologies in clinical and translational research; educate their trainees and the scientific community broadly about biomedical ontology and ontology-based technology and best practices; and collaborate with a variety of groups who develop and use ontologies and terminologies in biomedicine. The centerpiece of the National Center for Biomedical Ontology is a web-based resource known as BioPortal. BioPortal makes available for research in computationally useful forms more than 270 of the world's biomedical ontologies and terminologies, and supports a wide range of web services that enable investigators to use the ontologies to annotate and retrieve data, to generate value sets and special-purpose lexicons, and to perform advanced analytics on a wide range of biomedical data.},
author = {Musen, Mark A. and Noy, Natalya F. and Shah, Nigam H. and Whetzel, Patricia L. and Chute, Christopher G. and Story, Margaret Anne and Smith, Barry},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Musen et al. - 2012.pdf:pdf},
journal = {J. Am. Med. Informatics Assoc.},
number = {2},
pages = {190--195},
title = {{The National center for biomedical ontology}},
volume = {19},
year = {2012}
}
@article{Mungall2017,
abstract = {The correlation of phenotypic outcomes with genetic variation and environmental factors is a core pursuit in biology and biomedicine. Numerous challenges impede our progress: patient phenotypes may not match known diseases, candidate variants may be in genes that have not been characterized, model organisms may not recapitulate human or veterinary diseases, filling evolutionary gaps is difficult, and many resources must be queried to find potentially significant genotype-phenotype associations. Non-human organisms have proven instrumental in revealing biological mechanisms. Advanced informatics tools can identify phenotypically relevant disease models in research and diagnostic contexts. Large-scale integration of model organism and clinical research data can provide a breadth of knowledge not available from individual sources and can provide contextualization of data back to these sources. The Monarch Initiative (monarchinitiative.org) is a collaborative, open science effort that aims to semantically integrate genotype-phenotype data from many species and sources in order to support precision medicine, disease modeling, and mechanistic exploration. Our integrated knowledge graph, analytic tools, and web services enable diverse users to explore relationships between phenotypes and genotypes across species.},
author = {Mungall, Christopher J. and McMurry, Julie A. and Kohler, Sebastian and Balhoff, James P. and Borromeo, Charles and Brush, Matthew and Carbon, Seth and Conlin, Tom and Dunn, Nathan and Engelstad, Mark and Foster, Erin and Gourdine, J. P. and Jacobsen, Julius O.B. and Keith, Dan and Laraway, Bryan and Lewis, Suzanna E. and Xuan, Jeremy Nguyen and Shefchek, Kent and Vasilevsky, Nicole and Yuan, Zhou and Washington, Nicole and Hochheiser, Harry and Groza, Tudor and Smedley, Damian and Robinson, Peter N. and Haendel, Melissa A.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Mungall et al. - 2017.pdf:pdf},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {D712--D722},
title = {{The Monarch Initiative: An integrative data and analytic platform connecting phenotypes to genotypes across species}},
volume = {45},
year = {2017}
}
@misc{SCA2_GHR,
author = {{Genetics Home Reference}},
title = {{Spinocerebellar ataxia type 2}},
url = {https://ghr.nlm.nih.gov/condition/spinocerebellar-ataxia-type-2{\#}resources},
urldate = {2020-05-05}
}
@article{Amith2018,
abstract = {With the proliferation of heterogeneous health care data in the last three decades, biomedical ontologies and controlled biomedical terminologies play a more and more important role in knowledge representation and management, data integration, natural language processing, as well as decision support for health information systems and biomedical research. Biomedical ontologies and controlled terminologies are intended to assure interoperability. Nevertheless, the quality of biomedical ontologies has hindered their applicability and subsequent adoption in real-world applications. Ontology evaluation is an integral part of ontology development and maintenance. In the biomedicine domain, ontology evaluation is often conducted by third parties as a quality assurance (or auditing) effort that focuses on identifying modeling errors and inconsistencies. In this work, we first organized four categorical schemes of ontology evaluation methods in the existing literature to create an integrated taxonomy. Further, to understand the ontology evaluation practice in the biomedicine domain, we reviewed a sample of 200 ontologies from the National Center for Biomedical Ontology (NCBO) BioPortal—the largest repository for biomedical ontologies—and observed that only 15 of these ontologies have documented evaluation in their corresponding inception papers. We then surveyed the recent quality assurance approaches for biomedical ontologies and their use. We also mapped these quality assurance approaches to the ontology evaluation criteria. It is our anticipation that ontology evaluation and quality assurance approaches will be more widely adopted in the development life cycle of biomedical ontologies.},
author = {Amith, Muhammad and He, Zhe and Bian, Jiang and Lossio-Ventura, Juan Antonio and Tao, Cui},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Amith et al. - 2018.pdf:pdf},
journal = {J. Biomed. Inform.},
keywords = {Biomedical ontologies,Knowledge representation,Ontology evaluation,Quality assurance},
number = {August 2017},
pages = {1--13},
publisher = {Elsevier},
title = {{Assessing the practice of biomedical ontology evaluation: Gaps and opportunities}},
volume = {80},
year = {2018}
}
@misc{Docker2019,
author = {{Docker Inc.}},
title = {{Docker Community Edition}},
year = {2019}
}
@misc{SCA2_EFO,
author = {EFO},
title = {{Spinocerebellar ataxia type 2}},
url = {https://www.ebi.ac.uk/ols/ontologies/efo/terms?short{\_}form=Orphanet{\_}98756},
urldate = {2020-05-05}
}
@article{Schriml2015,
author = {Schriml, Lynn M and Mitraka, Elvira},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Schriml, Mitraka - 2015.pdf:pdf},
journal = {Mamm. Genome},
number = {9},
pages = {584--589},
publisher = {Springer US},
title = {{The Disease Ontology : fostering interoperability between biological and clinical human disease-related data}},
volume = {26},
year = {2015}
}
@article{Hoehndorf2013,
abstract = {Ontologies are now pervasive in biomedicine, where they serve as a means to standardize terminology, to enable access to domain knowledge, to verify data consistency and to facilitate integrative analyses over heterogeneous biomedical data. For this purpose, research on biomedical ontologies applies theories andmethods from diverse disciplines such as information management, knowledge representation, cognitive science, linguistics and philosophy. Depending on the desired applications in which ontologies are being applied, the evaluation of research in biomedical ontologies must follow different strategies. Here, we provide a classification of research problems in which ontologies are being applied, focusing on the use of ontologies in basic and translational research, and we demonstrate how research results in biomedical ontologies can be evaluated.The evaluation strategies depend on the desired application and measure the success of using an ontology for a particular biomedical problem. For many applications, the success can be quantified, thereby facilitating the objective evaluation and comparison of research in biomedical ontology. The objective, quantifiable comparison of research results based on scientific applications opens up the possibility for systematically improving the utility of ontologies in biomedical research. {\textcopyright} The Author 2012. Published by Oxford University Press.},
author = {Hoehndorf, Robert and Dumontier, Michel and Gkoutos, Georgios V.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Hoehndorf, Dumontier, Gkoutos - 2013.pdf:pdf},
journal = {Brief. Bioinform.},
keywords = {Biomedical ontology,Evaluation criteria,Ontology evaluation,Ontology-based applications,Quantitative biology},
number = {6},
pages = {696--712},
title = {{Evaluation of research in biomedical ontologies}},
volume = {14},
year = {2013}
}
@article{Dziak2019,
abstract = {Choosing a model with too few parameters can involve making unreal- istically simple assumptions and lead to high bias, poor prediction, and missed opportunities for insight. Such models are not flexible enough to describe the sample or the population well. A model with too many parameters can fit the observed data very well, but be too closely tai- lored to it. Such models may generalize poorly. Penalized-likelihood information criteria, such as Akaike's Information Criterion (AIC), the Bayesian Information Criterion (BIC), the Consistent AIC, and the Adjusted BIC, are widely used for model selection. However, differ- ent criteria sometimes support different models, leading to uncertainty about which criterion is the most trustworthy. In some simple cases the comparison of two models using information criteria can be viewed as equivalent to a likelihood ratio test, with the different models repre- senting different alpha levels (i.e., different emphases on sensitivity or specificity; Lin {\&} Dayton 1997). This perspective may lead to insights about how to interpret the criteria in less simple situations. For ex- ample, AIC or BIC could be preferable, depending on sample size and on the relative importance one assigns to sensitivity versus specificity. Understanding the differences among the criteria may make it easier to compare their results and to use them to make informed decisions.},
author = {Dziak, John J and Coffman, Donna L and Lanza, Stephanie T and Li, Runze and Jermiin, Lars S},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Dziak et al. - 2019.pdf:pdf},
journal = {Brief. Bioinform.},
number = {814},
title = {{Sensitivity and specificity of information criteria}},
year = {2019}
}
@misc{Xie2019,
author = {Xie, Yihui and Cheng, Joe and Tan, Xianying},
title = {{DT: a wrapper for the JavaScript Library "DataTables"}},
url = {https://cran.r-project.org/package=DT},
year = {2019}
}
@misc{Ren2016,
author = {Ren, Kun},
title = {rlist: a toolbox from non-tabular data manipulation},
url = {https://cran.r-project.org/package=rlist},
year = {2016}
}
@article{Schriml2012,
abstract = {The Disease Ontology (DO) database (http:// disease-ontology.org) represents a comprehensive knowledge base of 8043 inherited, developmental and acquired human diseases (DO version 3, revision 2510). The DO web browser has been designed for speed, efficiency and robustness through the use of a graph database. Full-text contextual searching functionality using Lucene allows the querying of name, synonym, definition, DOID and cross-reference (xrefs) with complex Boolean search strings. The DO semantically integrates disease and medical vocabularies through extensive cross mapping and integration of MeSH, ICD, NCI{\^{a}}€™s thesaurus, SNOMED CT and OMIM disease-specific terms and identifiers. The DO is utilized for disease annotation by major biomedical databases (e.g. Array Express, NIF, IEDB), as a standard representation of human disease in biomedical ontologies (e.g. IDO, Cell line ontology, NIFSTD ontology, Experimental Factor Ontology, Influenza Ontology), and as an ontological cross mappings resource between DO, MeSH and OMIM (e.g. GeneWiki). The DO project (http://diseaseontology.sf.net) has been incorporated into open source tools (e.g. Gene Answers, FunDO) to connect gene and disease biomedical data through the lens of human disease. The next iteration of the DO web browser will integrate DO{\^{a}}€™s extended relations and logical definition representation along with these biomedical resource cross-mappings. {\textcopyright} The Author(s) 2011.},
author = {Schriml, Lynn Marie and Arze, Cesar and Nadendla, Suvarna and Chang, Yu Wei Wayne and Mazaitis, Mark and Felix, Victor and Feng, Gang and Kibbe, Warren Alden},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Schriml et al. - 2012.pdf:pdf},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {940--946},
title = {{Disease ontology: A backbone for disease semantic integration}},
volume = {40},
year = {2012}
}
@article{Gruber1993,
author = {Gruber, Thomas R},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Gruber - 1993.pdf:pdf},
journal = {Knowl. Aquis.},
number = {2},
pages = {199--220},
title = {{A Translation Approach to Portable Ontology Specifications}},
volume = {5},
year = {1993}
}
@article{Landrum2018,
abstract = {ClinVar (https://www.ncbi.nlm.nih.gov/clinvar/) is a freely available, public archive of human genetic variants and interpretations of their significance to disease, maintained at the National Institutes of Health. Interpretations of the clinical significance of variants are submitted by clinical testing laboratories, research laboratories, expert panels and other groups. ClinVar aggregates data by variant-disease pairs, and by variant (or set of variants). Data aggregated by variant are accessible on the website, in an improved set of variant call format files and as a new comprehensive XML report. ClinVar recently started accepting submissions that are focused primarily on providing phenotypic information for individuals who have had genetic testing. Submissions may come from clinical providers providing their own interpretation of the variant ('provider interpretation') or from groups such as patient registries that primarily provide phenotypic information from patients ('phenotyping only'). ClinVar continues to make improvements to its search and retrieval functions. Several new fields are now indexed for more precise searching, and filters allow the user to narrow down a large set of search results.},
author = {Landrum, Melissa J. and Lee, Jennifer M. and Benson, Mark and Brown, Garth R. and Chao, Chen and Chitipiralla, Shanmuga and Gu, Baoshan and Hart, Jennifer and Hoffman, Douglas and Jang, Wonhee and Karapetyan, Karen and Katz, Kenneth and Liu, Chunlei and Maddipatla, Zenith and Malheiro, Adriana and McDaniel, Kurt and Ovetsky, Michael and Riley, George and Zhou, George and Holmes, J. Bradley and Kattman, Brandi L. and Maglott, Donna R.},
doi = {10.1093/nar/gkx1153},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Landrum et al. - 2018.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {D1062--D1067},
pmid = {29165669},
publisher = {Oxford University Press},
title = {{ClinVar: Improving access to variant interpretations and supporting evidence}},
volume = {46},
year = {2018}
}
@misc{Neo4j2020,
author = {{Neo4J Inc}},
title = {{Neo4j Community Edition}},
year = {2020}
}
@misc{R2019,
address = {Vienna, Austria},
author = {{R Core Team}},
publisher = {R Foundation for Statistical Computing},
title = {{R: A Language and Environment for Statistical Computing}},
url = {https://www.r-project.org/},
year = {2019}
}
@article{Shah2012,
abstract = {Advanced statistical methods used to analyze high-throughput data such as gene-expression assays result in long lists of "significant genes." One way to gain insight into the significance of altered expression levels is to determine whether Gene Ontology (GO) terms associated with a particular biological process, molecular function, or cellular component are over- or under-represented in the set of genes deemed significant. This process, referred to as enrichment analysis, profiles a gene-set, and is widely used to makes sense of the results of high-throughput experiments. The canonical example of enrichment analysis is when the output dataset is a list of genes differentially expressed in some condition. To determine the biological relevance of a lengthy gene list, the usual solution is to perform enrichment analysis with the GO. We can aggregate the annotating GO concepts for each gene in this list, and arrive at a profile of the biological processes or mechanisms affected by the condition under study. While GO has been the principal target for enrichment analysis, the methods of enrichment analysis are generalizable. We can conduct the same sort of profiling along other ontologies of interest. Just as scientists can ask "Which biological process is over-represented in my set of interesting genes or proteins?" we can also ask "Which disease (or class of diseases) is over-represented in my set of interesting genes or proteins?". For example, by annotating known protein mutations with disease terms from the ontologies in BioPortal, Mort et al. recently identified a class of diseases-blood coagulation disorders-that were associated with a 14-fold depletion in substitutions at O-linked glycosylation sites. With the availability of tools for automatic annotation of datasets with terms from disease ontologies, there is no reason to restrict enrichment analyses to the GO. In this chapter, we will discuss methods to perform enrichment analysis using any ontology available in the biomedical domain. We will review the general methodology of enrichment analysis, the associated challenges, and discuss the novel translational analyses enabled by the existence of public, national computational infrastructure and by the use of disease ontologies in such analyses. {\textcopyright} 2012 Shah et al.},
author = {Shah, Nigam H. and Cole, Tyler and Musen, Mark A.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Shah, Cole, Musen - 2012.pdf:pdf},
journal = {PLoS Comput. Biol.},
number = {12},
title = {{Chapter 9: Analyses Using Disease Ontologies}},
volume = {8},
year = {2012}
}
@article{Rappaport2013,
abstract = {Comprehensive disease classification, integration and annotation are crucial for biomedical discovery. At present, disease compilation is incomplete, heterogeneous and often lacking systematic inquiry mechanisms. We introduce MalaCards, an integrated database of human maladies and their annotations, modeled on the architecture and strategy of the GeneCards database of human genes. MalaCards mines and merges 44 data sources to generate a computerized card for each of 16 919 human diseases. Each MalaCard contains disease-specific prioritized annotations, as well as inter-disease connections, empowered by the GeneCards relational database, its searches and GeneDecks set analyses. First, we generate a disease list from 15 ranked sources, using disease-name unification heuristics. Next, we use four schemes to populate MalaCards sections: (i) directly interrogating disease resources, to establish integrated disease names, synonyms, summaries, drugs/therapeutics, clinical features, genetic tests and anatomical context; (ii) searching GeneCards for related publications, and for associated genes with corresponding relevance scores; (iii) analyzing disease-associated gene sets in GeneDecks to yield affiliated pathways, phenotypes, compounds and GO terms, sorted by a composite relevance score and presented with GeneCards links; and (iv) searching within MalaCards itself, e.g. for additional related diseases and anatomical context. The latter forms the basis for the construction of a disease network, based on shared MalaCards annotations, embodying associations based on etiology, clinical features and clinical conditions. This broadly disposed network has a power-law degree distribution, suggesting that this might be an inherent property of such networks. Work in progress includes hierarchical malady classification, ontological mapping and disease set analyses, striving to make MalaCards an even more effective tool for biomedical research. {\textcopyright} The Author(s) 2013. Published by Oxford University Press.},
author = {Rappaport, Noa and Nativ, Noam and Stelzer, Gil and Twik, Michal and Guan-Golan, Yaron and Stein, Tsippi Iny and Bahir, Iris and Belinky, Frida and Morrey, C. Paul and Safran, Marilyn and Lancet, Doron},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Rappaport et al. - 2013.pdf:pdf},
journal = {Database},
pages = {1--14},
title = {{MalaCards: An integrated compendium for diseases and their annotation}},
volume = {2013},
year = {2013}
}
@article{Livingston2015,
abstract = {Background: The ability to query many independent biological databases using a common ontology-based semantic model would facilitate deeper integration and more effective utilization of these diverse and rapidly growing resources. Despite ongoing work moving toward shared data formats and linked identifiers, significant problems persist in semantic data integration in order to establish shared identity and shared meaning across heterogeneous biomedical data sources. Results: We present five processes for semantic data integration that, when applied collectively, solve seven key problems. These processes include making explicit the differences between biomedical concepts and database records, aggregating sets of identifiers denoting the same biomedical concepts across data sources, and using declaratively represented forward-chaining rules to take information that is variably represented in source databases and integrating it into a consistent biomedical representation. We demonstrate these processes and solutions by presenting KaBOB (the Knowledge Base Of Biomedicine), a knowledge base of semantically integrated data from 18 prominent biomedical databases using common representations grounded in Open Biomedical Ontologies. An instance of KaBOB with data about humans and seven major model organisms can be built using on the order of 500 million RDF triples. All source code for building KaBOB is available under an open-source license. Conclusions: KaBOB is an integrated knowledge base of biomedical data representationally based in prominent, actively maintained Open Biomedical Ontologies, thus enabling queries of the underlying data in terms of biomedical concepts (e.g., genes and gene products, interactions and processes) rather than features of source-specific data schemas or file formats. KaBOB resolves many of the issues that routinely plague biomedical researchers intending to work with data from multiple data sources and provides a platform for ongoing data integration and development and for formal reasoning over a wealth of integrated biomedical data.},
author = {Livingston, Kevin M and Bada, Michael and Baumgartner, William A. and Hunter, Lawrence E},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Livingston et al. - 2015.pdf:pdf},
journal = {BMC Bioinformatics},
keywords = {Biomedical,Databases,Knowledge representation and reasoning,OWL,Open biomedical ontologies,RDF,Semantic data integration,Semantic web},
number = {1},
pages = {1--21},
title = {{KaBOB: ontology-based semantic integration of biomedical databases}},
volume = {16},
year = {2015}
}
@misc{Dgraph2017,
author = {Dgraph},
publisher = {[Last visit 26/12/2019]},
title = {{Dgraph graphical database}},
url = {https://docs.dgraph.io/},
year = {2017}
}
@article{Csardi2006,
author = {Csardi, Gabor and Nepusz, Tamas},
journal = {InterJournal},
pages = {1695},
title = {{The igraph software package for complex network research}},
url = {http://igraph.org},
volume = {Compex Sys},
year = {2006}
}
@misc{Wickham2019b,
author = {Wickham, Hadly},
title = {stringr: simple, consistent wrappers for common string operations},
url = {https://cran.r-project.org/package=stringr},
year = {2019}
}
@misc{apoc2020,
author = {Bowman, Andrew and Vegter, Kees},
title = {{Path Expander}},
url = {http://neo4j-contrib.github.io/neo4j-apoc-procedures/3.5/path-finding/path-expander/},
urldate = {2020-05-04},
year = {2020}
}
@article{Mendez2019,
abstract = {ChEMBL is a large, open-access bioactivity database (https://www.ebi.ac.uk/chembl), previously described in the 2012, 2014 and 2017 Nucleic Acids Research Database Issues. In the last two years, several important improvements have been made to the database and are described here. These include more robust capture and representation of assay details; a new data deposition system, allowing updating of data sets and deposition of supplementary data; and a completely redesignedweb interface, with enhanced search and filtering capabilities.},
author = {Mendez, David and Gaulton, Anna and Bento, A. Patr{\'{i}}cia and Chambers, Jon and {De Veij}, Marleen and F{\'{e}}lix, Eloy and Magari{\~{n}}os, Mar{\'{i}}a Paula and Mosquera, Juan F. and Mutowo, Prudence and Nowotka, Micha{\l} and Gordillo-Mara{\~{n}}{\'{o}}n, Mar{\'{i}}a and Hunter, Fiona and Junco, Laura and Mugumbate, Grace and Rodriguez-Lopez, Milagros and Atkinson, Francis and Bosc, Nicolas and Radoux, Chris J. and Segura-Cabrera, Aldo and Hersey, Anne and Leach, Andrew R.},
doi = {10.1093/nar/gky1075},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Mendez et al. - 2019.pdf:pdf},
issn = {13624962},
journal = {Nucleic Acids Res.},
number = {D1},
pages = {D930--D940},
pmid = {30398643},
title = {{ChEMBL: Towards direct deposition of bioassay data}},
volume = {47},
year = {2019}
}
@misc{Chang2019,
author = {Chang, Winston and Cheng, Joe and Allaire, JJ and Xie, Yihui and McPherson, Jonathan},
title = {{shiny: Web Application Framework for R}},
url = {https://cran.r-project.org/package=shiny},
year = {2019}
}
@article{Kock-Schoppenhauer2017,
abstract = {Clinical care and research data are widely dispersed in isolated systems based on heterogeneous data models. Biomedicine predominantly makes use of connected datasets based on the Semantic Web paradigm. Initiatives like Bio2RDF created Resource Description Framework (RDF) versions of Omics resources, enabling sophisticated Linked Data applications. In contrast, electronic healthcare records (EHR) data are generated and processed in diverse clinical subsystems within hospital information systems (HIS). Usually, each of them utilizes a relational database system with a different proprietary schema. Semantic integration and access to the data is hardly possible. This paper describes ways of using Ontology Based Data Access (OBDA) for bridging the semantic gap between existing raw data and user-oriented views supported by ontology-based queries. Based on mappings between entities of data schemas and ontologies data can be made available as materialized or virtualized RDF triples ready for querying and processing. Our experiments based on CentraXX for biobank and study management demonstrate the advantages of abstracting away from low level details and semantic mediation. Furthermore, it becomes clear that using a professional platform for Linked Data applications is recommended due to the inherent complexity, the inconvenience to confront end users with SPARQL, and scalability and performance issues.},
author = {Kock-Schoppenhauer, Ann Kristin and Kamann, Christian and Ulrich, Hannes and Duhm-Harbeck, Petra and Ingenerf, Josef},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Kock-Schoppenhauer et al. - 2017.pdf:pdf},
journal = {Stud. Health Technol. Inform.},
keywords = {Linked Data,Semantic Querying and Data Integration,Semantic Web},
pages = {131--135},
title = {{Linked Data Applications Through Ontology Based Data Access in Clinical Research}},
volume = {235},
year = {2017}
}
@article{Mungall2010,
abstract = {Phenotype ontologies are typically constructed to serve the needs of a particular community, such as annotation of genotype-phenotype associations in mouse or human. Here we demonstrate how these ontologies can be improved through assignment of logical definitions using a core ontology of phenotypic qualities and multiple additional ontologies from the Open Biological Ontologies library. We also show how these logical definitions can be used for data integration when combined with a unified multi-species anatomy ontology.},
author = {Mungall, Christopher J. and Gkoutos, Georgios V. and Smith, Cynthia L. and Haendel, Melissa A. and Lewis, Suzanna E. and Ashburner, Michael},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Mungall et al. - 2010.pdf:pdf},
journal = {Genome Biol.},
number = {1},
pages = {1--16},
title = {{Integrating phenotype ontologies across multiple species}},
volume = {11},
year = {2010}
}
@article{Adamusiak2011,
author = {Adamusiak, Tomasz and Kurnosov, Pavel and Swertz, Morris and Kapushesky, Misha},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Adamusiak et al. - 2011(2).pdf:pdf},
pages = {1--6},
title = {{ontoCAT : package for basic operations with ontologies}},
year = {2011}
}
@misc{SCA2-MONDO,
author = {{Monarch Initiative}},
title = {spinocerebellar ataxia type 2},
url = {https://rdf.monarchinitiative.org/disease/MONDO:0008458},
urldate = {2020-05-05}
}
@article{Yu2015,
abstract = {Disease ontology (DO) annotates human genes in the context of disease. DO is important annotation in translating molecular findings from high-throughput data to clinical relevance. DOSE is an R package providing semantic similarity computations among DO terms and genes which allows biologists to explore the similarities of diseases and of gene functions in disease perspective. Enrichment analyses including hypergeometric model and gene set enrichment analysis are also implemented to support discovering disease associations of high-throughput biological data. This allows biologists to verify disease relevance in a biological experiment and identify unexpected disease associations.},
author = {Yu, Guangchuang and Wang, Li Gen and Yan, Guang Rong and He, Qing Yu},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Yu et al. - 2015.pdf:pdf},
journal = {Bioinformatics},
number = {4},
pages = {608--609},
title = {{DOSE: An R/Bioconductor package for disease ontology semantic and enrichment analysis}},
volume = {31},
year = {2015}
}
@misc{Almende2019,
author = {{Almende B.V.} and Thieurmel, Benoit and Robert, Titouan},
title = {{visNetwork: network visualization using vis.js library}},
url = {https://cran.r-project.org/package=visNetwork},
year = {2019}
}
@article{Malone2010,
abstract = {Motivation: Describing biological sample variables with ontologies is complex due to the cross-domain nature of experiments. Ontologies provide annotation solutions; however, for cross-domain investigations, multiple ontologies are needed to represent the data. These are subject to rapid change, are often not interoperable and present complexities that are a barrier to biological resource users. Results: We present the Experimental Factor Ontology, designed to meet cross-domain, application focused use cases for gene expression data. We describe our methodology and open source tools used to create the ontology. These include tools for creating ontology mappings, ontology views, detecting ontology changes and using ontologies in interfaces to enhance querying. The application of reference ontologies to data is a key problem, and this work presents guidelines on how community ontologies can be presented in an application ontology in a data-driven way. Availability: http://www.ebi.ac.uk/efo. Contact: malone@ebi.ac.uk. Supplementary information: Supplementary data are available at Bioinformatics online. {\textcopyright} The Author(s) 2010. Published by Oxford University Press.},
author = {Malone, James and Holloway, Ele and Adamusiak, Tomasz and Kapushesky, Misha and Zheng, Jie and Kolesnikov, Nikolay and Zhukova, Anna and Brazma, Alvis and Parkinson, Helen},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Malone et al. - 2010.pdf:pdf},
journal = {Bioinformatics},
number = {8},
pages = {1112--1118},
title = {{Modeling sample variables with an Experimental Factor Ontology}},
volume = {26},
year = {2010}
}
@article{McMurry2017,
abstract = {In many disciplines, data are highly decentralized across thousands of online databases (repositories, registries, and knowledgebases). Wringing value from such databases depends on the discipline of data science and on the humble bricks and mortar that make integration possible; identifiers are a core component of this integration infrastructure. Draw-ing on our experience and on work by other groups, we outline 10 lessons we have learned about the identifier qualities and best practices that facilitate large-scale data integration. Citation: McMurry JA, Juty N, Blomberg N, Burdett T, Conlin T, Conte N, et al. (2017) Identifiers for the 21st century: How to design, provision, and reuse persistent identifiers to maximize utility and impact of life science data. PLoS Biol 15(6): e2001414.},
author = {McMurry, Julie A. and Juty, Nick and Blomberg, Niklas and Burdett, Tony and Conlin, Tom and Conte, Nathalie and Courtot, M{\'{e}}lanie and Deck, John and Dumontier, Michel and Fellows, Donal K. and Gonzalez-Beltran, Alejandra and Gormanns, Philipp and Grethe, Jeffrey and Hastings, Janna and H{\'{e}}rich{\'{e}}, Jean Karim and Hermjakob, Henning and Ison, Jon C. and Jimenez, Rafael C. and Jupp, Simon and Kunze, John and Laibe, Camille and {Le Nov{\`{e}}re}, Nicolas and Malone, James and Martin, Maria Jesus and McEntyre, Johanna R. and Morris, Chris and Muilu, Juha and M{\"{u}}ller, Wolfgang and Rocca-Serra, Philippe and Sansone, Susanna Assunta and Sariyar, Murat and Snoep, Jacky L. and Soiland-Reyes, Stian and Stanford, Natalie J. and Swainston, Neil and Washington, Nicole and Williams, Alan R. and Wimalaratne, Sarala M. and Winfree, Lilly M. and Wolstencroft, Katherine and Goble, Carole and Mungall, Christopher J. and Haendel, Melissa A. and Parkinson, Helen},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/McMurry et al. - 2017.pdf:pdf},
journal = {PLoS Biol.},
number = {6},
pages = {1--18},
title = {{Identifiers for the 21st century: How to design, provision, and reuse persistent identifiers to maximize utility and impact of life science data}},
volume = {15},
year = {2017}
}
@misc{Chang2018,
author = {Chang, Winston},
title = {shinythemes: themes for shiny},
url = {https://cran.r-project.org/package=shinythemes},
year = {2018}
}
@article{Washington2009,
abstract = {Scientists and clinicians who study genetic alterations and disease have traditionally described phenotypes in natural language. The considerable variation in these free-text descriptions has posed a hindrance to the important task of identifying candidate genes and models for human diseases and indicates the need for a computationally tractable method to mine data resources for mutant phenotypes. In this study, we tested the hypothesis that ontological annotation of disease phenotypes will facilitate the discovery of new genotype-phenotype relationships within and across species. To describe phenotypes using ontologies, we used an Entity-Quality (EQ) methodology, wherein the affected entity (E) and how it is affected (Q) are recorded using terms from a variety of ontologies. Using this EQ method, we annotated the phenotypes of 11 gene-linked human diseases described in Online Mendelian Inheritance in Man (OMIM). These human annotations were loaded into our Ontology-Based Database (OBD) along with other ontology-based phenotype descriptions of mutants from various model organism databases. Phenotypes recorded with this EQ method can be computationally compared based on the hierarchy of terms in the ontologies and the frequency of annotation. We utilized four similarity metrics to compare phenotypes and developed an ontology of homologous and analogous anatomical structures to compare phenotypes between species. Using these tools, we demonstrate that we can identify, through the similarity of the recorded phenotypes, other alleles of the same gene, other members of a signaling pathway, and orthologous genes and pathway members across species. We conclude that EQ-based annotation of phenotypes, in conjunction with a cross-species ontology, and a variety of similarity metrics can identify biologically meaningful similarities between genes by comparing phenotypes alone. This annotation and search method provides a novel and efficient means to identify gene candidates and animal models of human disease, which may shorten the lengthy path to identification and understanding of the genetic basis of human disease.},
author = {Washington, Nicole L. and Haendel, Melissa A. and Mungall, Christopher J. and Ashburner, Michael and Westerfield, Monte and Lewis, Suzanna E.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Washington et al. - 2009.pdf:pdf},
journal = {PLoS Biol.},
number = {11},
title = {{Linking human diseases to animal models using ontology-based phenotype annotation}},
volume = {7},
year = {2009}
}
@article{Francois2020b,
author = {Fran{\c{c}}ois, Liesbeth},
journal = {Zenodo},
title = {docker-ucb-public-dodo-20.04.2020 (version 20/04/2020)},
year = {2020}
}
@misc{Wickham2019a,
author = {Wickham, Hadly and Henry, Lionel},
title = {tidyr: tidy messy data},
url = {https://cran.r-project.org/package=tidyr},
year = {2019}
}
@misc{EFO2019,
author = {Ochoa, David},
publisher = {[Last visit 26/12/2019]},
title = {{EFO3: A community-driven ontology to advance clinical discoveries}},
url = {https://blog.opentargets.org/2019/12/19/efo3-a-community-driven-ontology-to-advance-clinical-discoveries/},
year = {2019}
}
@article{Hodos2016,
abstract = {Synapses are highly plastic and are modified by changes in patterns of neural activity or sensory experience. Plasticity of cortical excitatory synapses is thought to be important for learning and memory, leading to alterations in sensory representations and cognitive maps. However, these changes must be coordinated across other synapses within local circuits to preserve neural coding schemes and the organization of excitatory and inhibitory inputs, i.e., excitatory-inhibitory balance. Recent studies indicate that inhibitory synapses are also plastic and are controlled directly by a large number of neuromodulators, particularly during episodes of learning. Many modulators transiently alter excitatory-inhibitory balance by decreasing inhibition, and thus disinhibition has emerged as a major mechanism by which neuromodulation might enable long-term synaptic modifications naturally. This review examines the relationships between neuromodulation and synaptic plasticity, focusing on the induction of long-term changes that collectively enhance cortical excitatory-inhibitory balance for improving perception and behavior. Keywords},
author = {Hodos, R A and Kidd, B A and Khader, S and Readhead, B P and Dudley, J T},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Hodos et al. - 2016.pdf:pdf},
journal = {HHS Public Acces},
title = {{Computational Approaches to Drug Repurposing and Pharmacology}},
year = {2016}
}
@article{LePendu2011,
abstract = {Advanced statistical methods used to analyze high-throughput data such as gene-expression assays result in long lists of "significant genes." One way to gain insight into the significance of altered expression levels is to determine whether Gene Ontology (GO) terms associated with a particular biological process, molecular function, or cellular component are over- or under-represented in the set of genes deemed significant. This process, referred to as enrichment analysis, profiles a gene set, and is widely used to make sense of the results of high-throughput experiments. Our goal is to develop and apply general enrichment analysis methods to profile other sets of interest, such as patient cohorts from the electronic medical record, using a variety of ontologies including SNOMED CT, MedDRA, RxNorm, and others. Although it is possible to perform enrichment analysis using ontologies other than the GO, a key pre-requisite is the availability of a background set of annotations to enable the enrichment calculation. In the case of the GO, this background set is provided by the Gene Ontology Annotations. In the current work, we describe: (i) a general method that uses hand-curated GO annotations as a starting point for creating background datasets for enrichment analysis using other ontologies; and (ii) a gene-disease background annotation set - that enables disease-based enrichment - to demonstrate feasibility of our method. {\textcopyright} 2011 Elsevier Inc.},
author = {LePendu, Paea and Musen, Mark A. and Shah, Nigam H.},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/LePendu, Musen, Shah - 2011.pdf:pdf},
journal = {J. Biomed. Inform.},
keywords = {Annotation,Electronic Health Records,Enrichment analysis,Human disease,Information integration,Ontology},
number = {SUPPL. 1},
pages = {S31--S38},
publisher = {Elsevier Inc.},
title = {{Enabling enrichment analysis with the Human Disease Ontology}},
volume = {44},
year = {2011}
}
@article{Shefchek2019,
author = {Shefchek, Kent A and Harris, Nomi L and Gargano, Michael and Matentzoglu, Nicolas and Unni, Deepak and Brush, Matthew and Keith, Daniel and Conlin, Tom and Vasilevsky, Nicole and Zhang, Aaron and Balhoff, James P and Babb, Larry and Bello, Susan M and Blau, Hannah and Bradford, Yvonne and Carbon, Seth and Carmody, Leigh and Chan, Lauren E and Cipriani, Valentina and Cuzick, Alayne and Rocca, Maria D and Dunn, Nathan and Essaid, Shahim and Fey, Petra and Grove, Chris and Gourdine, Jean-phillipe and Hamosh, Ada and Harris, Midori and Helbig, Ingo and Hoatlin, Maureen and Joachimiak, Marcin and Jupp, Simon and Pendlington, M and Pilgrim, Clare and Lett, B and Lewis, Suzanna E and Mcnamara, Craig and Putman, Tim and Ravanmehr, Vida and Reese, Justin and Riggs, Erin and Robb, Sofia and Roncaglia, Paola and Seager, James and Segerdell, Erik and Similuk, Morgan and Storm, Andrea L and Thaxon, Courtney and Thessen, Anne and Jacobsen, Julius O B and Mcmurry, Julie A and Groza, Tudor and Sebastian, K and Smedley, Damian and Robinson, Peter N and Mungall, J and Haendel, Melissa A and Munoz-torres, Monica C and Osumi-sutherland, David},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Shefchek et al. - 2019.pdf:pdf},
journal = {Nucleic Acids Res.},
pages = {1--12},
title = {{The Monarch Initiative in 2019 : an integrative data and analytic platform connecting phenotypes to genotypes across species}},
volume = {1},
year = {2019}
}
@article{Conesa2016a,
abstract = {RNA-sequencing (RNA-seq) has a wide variety of applications, but no single analysis pipeline can be used in all cases. We review all of the major steps in RNA-seq data analysis, including experimental design, quality control, read alignment, quantification of gene and transcript levels, visualization, differential gene expression, alternative splicing, functional analysis, gene fusion detection and eQTL mapping. We highlight the challenges associated with each step. We discuss the analysis of small RNAs and the integration of RNA-seq with other functional genomics techniques. Finally, we discuss the outlook for novel technologies that are changing the state of the art in transcriptomics.},
author = {Conesa, Ana and Madrigal, Pedro and Tarazona, Sonia and Gomez-Cabrero, David and Cervera, Alejandra and McPherson, Andrew and Szcze{\'{s}}niak, Michal Wojciech and Gaffney, Daniel J. and Elo, Laura L. and Zhang, Xuegong and Mortazavi, Ali},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Conesa et al. - 2016.pdf:pdf},
journal = {Genome Biol.},
number = {1},
pages = {1--19},
title = {{A survey of best practices for RNA-seq data analysis}},
volume = {17},
year = {2016}
}
@article{Adamusiak2011a,
author = {Adamusiak, Tomasz and Kurbatova, Natalja and Swertz, Morris and Parkinson, Helen},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Adamusiak et al. - 2011.pdf:pdf},
journal = {Nat. Preced.},
pages = {2},
title = {{OntoCAT - an integrated programming toolkit for common ontology application tasks}},
year = {2011}
}
@article{Francois2020,
author = {Fran{\c{c}}ois, Liesbeth},
journal = {Zenodo},
title = {{Elysheba/DODO: publication (v1) release}},
year = {2020}
}
@article{Gros2016,
abstract = {Biomedical ontologies are heavily used to annotate data, and different ontologies are often interlinked by ontology mappings. These ontology-based mappings and annotations are used in many applications and analysis tasks. Since biomedical ontologies are continuously updated dependent artifacts can become outdated and need to undergo evolution as well. Hence there is a need for largely automated approaches to keep ontology-based mappings up-to-date in the presence of evolving ontologies. In this article, we survey current approaches and novel directions in the context of ontology and mapping evolution. We will discuss requirements for mapping adaptation and provide a comprehensive overview on existing approaches. We will further identify open challenges and outline ideas for future developments.},
author = {Gro{\ss}, Anika and Pruski, C{\'{e}}dric and Rahm, Erhard},
file = {:C$\backslash$:/Users/U060109.UCB-CORP/Dropbox/Mendeley/Gro{\ss}, Pruski, Rahm - 2016.pdf:pdf},
journal = {Comput. Struct. Biotechnol. J.},
keywords = {Biomedical annotation,Biomedical ontology,Mapping adaptation,Mapping evolution,Ontology evolution,Ontology-based mapping},
pages = {333--340},
publisher = {Natrix Separations},
title = {{Evolution of biomedical ontologies and mappings: Overview of recent approaches}},
volume = {14},
year = {2016}
}
